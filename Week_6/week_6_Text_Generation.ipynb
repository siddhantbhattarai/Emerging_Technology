{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6670782f-95bc-48f5-8352-20bb9a84dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install Transformers library\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e290cf2-6948-4f42-9e43-8af8bf924e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 08:22:16.137893: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Import required libraries\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a5b533-f3a4-4aaf-9713-607fd9917dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load a pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453438ba-219e-4da9-80ed-cb36913e724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure pad_token is set to eos_token to avoid warnings\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c30a99-7dae-43f4-95ec-8afdf757e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Function for generating text\n",
    "def generate_text(prompt, max_length=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.pad_token_id  # Explicitly set pad_token_id\n",
    "    )\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edc6080a-5fac-416d-b990-e381884b5540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Artificial Intelligence is\n",
      "Generated: Artificial Intelligence is a product of artificial intelligence researchers. In order to analyze their product and discover any real change from how their data would look, there will be an opportunity for the company to do that.\n",
      "\n",
      "Companies such as Samsung will face a\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Input: The future of technology\n",
      "Generated: The future of technology will eventually create new opportunities for people to connect with their communities and build online communities,\" he says. \"That will continue to play such a prominent role for many years.\"\n",
      "\n",
      "It's the first such effort for the U.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Input: Once upon a time\n",
      "Generated: Once upon a time, the world must look on in horror and despairâ€¦ The time is finally approaching and it is time to strike against the darkness which is taking shape beneath our feet.\"\n",
      "\n",
      "At the time, the most well known and trusted leader\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Try generating text for three inputs\n",
    "texts = [\"Artificial Intelligence is\", \"The future of technology\", \"Once upon a time\"]\n",
    "for text in texts:\n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"Generated: {generate_text(text)}\")\n",
    "    print(\"-\" * 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76edc7df-079d-43cf-a2a1-144c7b4dc109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
